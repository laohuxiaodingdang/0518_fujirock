#!/usr/bin/env python3
"""
Fuji Rock 2025 è‰ºæœ¯å®¶æ•°æ®æ”¶é›†è„šæœ¬ï¼ˆæ— æ•°æ®åº“ç‰ˆæœ¬ï¼‰

è¿™ä¸ªè„šæœ¬æ”¶é›† Fuji Rock 2025 çš„è‰ºæœ¯å®¶æ•°æ®å¹¶ä¿å­˜åˆ° JSON æ–‡ä»¶ä¸­ã€‚
ä¸ä¾èµ–æ•°æ®åº“è¿æ¥ï¼Œé€‚åˆç½‘ç»œç¯å¢ƒå—é™çš„æƒ…å†µã€‚

ä½¿ç”¨æ–¹æ³•ï¼š
python3 scripts/collect_fuji_rock_data.py
"""

import asyncio
import logging
import sys
import os
import json
from datetime import datetime
from typing import List, Dict, Any

# é¦–å…ˆåŠ è½½ç¯å¢ƒå˜é‡ï¼ˆåœ¨å¯¼å…¥ä»»ä½•é…ç½®ä¹‹å‰ï¼‰
from dotenv import load_dotenv
load_dotenv()

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

def serialize_for_json(obj):
    """
    å°†å¤æ‚å¯¹è±¡è½¬æ¢ä¸ºå¯ JSON åºåˆ—åŒ–çš„æ ¼å¼
    """
    if hasattr(obj, '__dict__'):
        # å¦‚æœå¯¹è±¡æœ‰ __dict__ å±æ€§ï¼Œè½¬æ¢ä¸ºå­—å…¸
        return obj.__dict__
    elif hasattr(obj, '_asdict'):
        # å¦‚æœæ˜¯ namedtupleï¼Œè½¬æ¢ä¸ºå­—å…¸
        return obj._asdict()
    elif isinstance(obj, (list, tuple)):
        # å¦‚æœæ˜¯åˆ—è¡¨æˆ–å…ƒç»„ï¼Œé€’å½’å¤„ç†æ¯ä¸ªå…ƒç´ 
        return [serialize_for_json(item) for item in obj]
    elif isinstance(obj, dict):
        # å¦‚æœæ˜¯å­—å…¸ï¼Œé€’å½’å¤„ç†æ¯ä¸ªå€¼
        return {key: serialize_for_json(value) for key, value in obj.items()}
    else:
        # å…¶ä»–æƒ…å†µï¼Œå°è¯•è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        try:
            json.dumps(obj)  # æµ‹è¯•æ˜¯å¦å¯ä»¥åºåˆ—åŒ–
            return obj
        except (TypeError, ValueError):
            return str(obj)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('fuji_rock_data_collection.log')
    ]
)

logger = logging.getLogger(__name__)

# Fuji Rock 2025 è‰ºæœ¯å®¶åå•ï¼ˆåŸºäºå®˜æ–¹ç½‘ç«™ï¼‰
FUJI_ROCK_2025_ARTISTS = [
    # ä¸»è¦è‰ºæœ¯å®¶
    "VAMPIRE",
    "Radiohead", 
    "Coldplay",
    "The Strokes",
    "Arctic Monkeys",
    "Tame Impala",
    "Mac Miller",
    "Tyler, The Creator",
    "Billie Eilish",
    "Lana Del Rey",
    
    # æ—¥æœ¬è‰ºæœ¯å®¶
    "ONE OK ROCK",
    "BABYMETAL",
    "King Gnu",
    "Yoasobi",
    "Officialé«­ç”·dism",
    
    # å…¶ä»–å›½é™…è‰ºæœ¯å®¶
    "Dua Lipa",
    "The Weeknd",
    "Post Malone",
    "Imagine Dragons",
    "Twenty One Pilots",
    "Foo Fighters",
    "Red Hot Chili Peppers",
    "Muse",
    "Gorillaz",
    "Beck"
]

async def collect_artist_data(artist_name: str) -> Dict[str, Any]:
    """
    æ”¶é›†å•ä¸ªè‰ºæœ¯å®¶çš„å®Œæ•´æ•°æ®
    
    Args:
        artist_name: è‰ºæœ¯å®¶åç§°
        
    Returns:
        Dict: è‰ºæœ¯å®¶çš„å®Œæ•´æ•°æ®
    """
    logger.info(f"ğŸ¤ å¼€å§‹æ”¶é›† {artist_name} çš„æ•°æ®...")
    
    result = {
        "artist_name": artist_name,
        "collected_at": datetime.now().isoformat(),
        "data": {},
        "success": True,
        "errors": []
    }
    
    try:
        from services.wikipedia_service import wikipedia_service
        from services.spotify_service import spotify_service
        from services.openai_service import openai_service
        
        # 1. æ”¶é›† Wikipedia æ•°æ®
        logger.info(f"  ğŸ“– è·å– Wikipedia æ•°æ®...")
        try:
            wiki_result = await wikipedia_service.get_artist_info(artist_name, "zh")
            if wiki_result:
                result["data"]["wikipedia"] = {
                    "title": wiki_result.title,
                    "extract": wiki_result.extract,
                    "thumbnail": wiki_result.thumbnail.source if wiki_result.thumbnail else None,
                    "categories": wiki_result.categories,
                    "references": [{"title": ref.title, "url": ref.url} for ref in wiki_result.references] if wiki_result.references else []
                }
                logger.info(f"    âœ… Wikipedia æ•°æ®æ”¶é›†æˆåŠŸ")
            else:
                result["errors"].append("Wikipedia data not found")
                logger.warning(f"    âš ï¸ Wikipedia æ•°æ®æœªæ‰¾åˆ°")
        except Exception as e:
            result["errors"].append(f"Wikipedia error: {str(e)}")
            logger.error(f"    âŒ Wikipedia æ•°æ®æ”¶é›†å¤±è´¥: {str(e)}")
        
        await asyncio.sleep(1)  # API é™åˆ¶
        
        # 2. æ”¶é›† Spotify æ•°æ®
        logger.info(f"  ğŸ§ è·å– Spotify æ•°æ®...")
        try:
            spotify_result = await spotify_service.get_artist_by_name(artist_name)
            if spotify_result.get("success"):
                spotify_data = spotify_result["data"]
                result["data"]["spotify"] = {
                    "id": spotify_data.get("id"),
                    "name": spotify_data.get("name"),
                    "popularity": spotify_data.get("popularity"),
                    "followers": spotify_data.get("followers", {}).get("total", 0),
                    "genres": spotify_data.get("genres", []),
                    "external_urls": spotify_data.get("external_urls", {}),
                    "images": spotify_data.get("images", [])
                }
                
                # è·å–çƒ­é—¨æ­Œæ›²
                spotify_id = spotify_data.get("id")
                if spotify_id:
                    await asyncio.sleep(1)
                    tracks_result = await spotify_service.get_artist_top_tracks(spotify_id, limit=5)
                    if tracks_result.get("success"):
                        result["data"]["spotify"]["top_tracks"] = tracks_result["data"]["tracks"]
                
                logger.info(f"    âœ… Spotify æ•°æ®æ”¶é›†æˆåŠŸ")
            else:
                result["errors"].append(f"Spotify error: {spotify_result.get('error')}")
                logger.warning(f"    âš ï¸ Spotify æ•°æ®æ”¶é›†å¤±è´¥: {spotify_result.get('error')}")
        except Exception as e:
            result["errors"].append(f"Spotify error: {str(e)}")
            logger.error(f"    âŒ Spotify æ•°æ®æ”¶é›†å¤±è´¥: {str(e)}")
        
        await asyncio.sleep(1)
        
        # 3. ç”Ÿæˆ AI æè¿°
        if result["data"].get("wikipedia"):
            logger.info(f"  ğŸ¤– ç”Ÿæˆ AI æè¿°...")
            try:
                wiki_extract = result["data"]["wikipedia"]["extract"]
                ai_result = await openai_service.generate_sassy_description(
                    artist_name=artist_name,
                    wiki_content=wiki_extract,
                    style_intensity=7,
                    language="zh"
                )
                if ai_result.get("success"):
                    result["data"]["ai_description"] = ai_result["data"]
                    logger.info(f"    âœ… AI æè¿°ç”ŸæˆæˆåŠŸ")
                else:
                    result["errors"].append(f"AI error: {ai_result.get('error')}")
                    logger.warning(f"    âš ï¸ AI æè¿°ç”Ÿæˆå¤±è´¥: {ai_result.get('error')}")
            except Exception as e:
                result["errors"].append(f"AI error: {str(e)}")
                logger.error(f"    âŒ AI æè¿°ç”Ÿæˆå¤±è´¥: {str(e)}")
        
        # 4. è®¡ç®—æ•°æ®å®Œæ•´æ€§
        data_sources = ["wikipedia", "spotify", "ai_description"]
        collected_sources = [source for source in data_sources if source in result["data"]]
        result["data_completeness"] = {
            "collected": len(collected_sources),
            "total": len(data_sources),
            "percentage": (len(collected_sources) / len(data_sources)) * 100,
            "sources": collected_sources
        }
        
        logger.info(f"âœ… {artist_name} æ•°æ®æ”¶é›†å®Œæˆ ({len(collected_sources)}/{len(data_sources)} æ•°æ®æº)")
        
    except Exception as e:
        result["success"] = False
        result["errors"].append(f"General error: {str(e)}")
        logger.error(f"âŒ {artist_name} æ•°æ®æ”¶é›†å¤±è´¥: {str(e)}")
    
    return result

async def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸ¸ Fuji Rock 2025 è‰ºæœ¯å®¶æ•°æ®æ”¶é›†å¼€å§‹")
    logger.info("="*80)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = "data/fuji_rock_2025"
    os.makedirs(output_dir, exist_ok=True)
    
    all_results = []
    successful_collections = 0
    
    # å¤„ç†è‰ºæœ¯å®¶åˆ—è¡¨
    total_artists = len(FUJI_ROCK_2025_ARTISTS)
    logger.info(f"ğŸ“ å°†æ”¶é›† {total_artists} ä¸ªè‰ºæœ¯å®¶çš„æ•°æ®")
    
    for i, artist in enumerate(FUJI_ROCK_2025_ARTISTS, 1):
        logger.info(f"\n{'='*60}")
        logger.info(f"è¿›åº¦: {i}/{total_artists} - {artist}")
        logger.info(f"{'='*60}")
        
        result = await collect_artist_data(artist)
        all_results.append(result)
        
        if result["success"]:
            successful_collections += 1
        
        # ä¿å­˜å•ä¸ªè‰ºæœ¯å®¶æ•°æ®
        artist_filename = f"{output_dir}/{artist.replace(' ', '_').replace(',', '').lower()}.json"
        with open(artist_filename, 'w', encoding='utf-8') as f:
            # ä½¿ç”¨åºåˆ—åŒ–å‡½æ•°å¤„ç†å¤æ‚å¯¹è±¡
            serializable_result = serialize_for_json(result)
            json.dump(serializable_result, f, ensure_ascii=False, indent=2)
        
        # å¤„ç†é—´éš”ï¼ˆé¿å… API é™åˆ¶ï¼‰
        if i < total_artists:
            logger.info("â³ ç­‰å¾… 2 ç§’...")
            await asyncio.sleep(2)
    
    # ä¿å­˜æ±‡æ€»æ•°æ®
    summary = {
        "collection_info": {
            "total_artists": total_artists,
            "successful_collections": successful_collections,
            "success_rate": (successful_collections / total_artists) * 100,
            "collected_at": datetime.now().isoformat(),
            "collection_duration": "N/A"  # å¯ä»¥æ·»åŠ æ—¶é—´è®¡ç®—
        },
        "artists": all_results
    }
    
    summary_filename = f"{output_dir}/fuji_rock_2025_summary.json"
    with open(summary_filename, 'w', encoding='utf-8') as f:
        # ä½¿ç”¨åºåˆ—åŒ–å‡½æ•°å¤„ç†å¤æ‚å¯¹è±¡
        serializable_summary = serialize_for_json(summary)
        json.dump(serializable_summary, f, ensure_ascii=False, indent=2)
    
    # è¾“å‡ºæœ€ç»ˆç»“æœ
    logger.info(f"\n{'='*80}")
    logger.info("ğŸµ æ•°æ®æ”¶é›†å®Œæˆï¼ç»“æœæ‘˜è¦:")
    logger.info(f"{'='*80}")
    
    logger.info(f"ğŸ“Š æ€»è®¡: {total_artists} ä¸ªè‰ºæœ¯å®¶")
    logger.info(f"âœ… æˆåŠŸ: {successful_collections}")
    logger.info(f"âŒ å¤±è´¥: {total_artists - successful_collections}")
    logger.info(f"ğŸ“ˆ æˆåŠŸç‡: {(successful_collections / total_artists * 100):.1f}%")
    
    # æ•°æ®å®Œæ•´æ€§ç»Ÿè®¡
    completeness_stats = {}
    for result in all_results:
        if result["success"] and "data_completeness" in result:
            percentage = result["data_completeness"]["percentage"]
            if percentage == 100:
                completeness_stats["å®Œæ•´"] = completeness_stats.get("å®Œæ•´", 0) + 1
            elif percentage >= 66:
                completeness_stats["è¾ƒå®Œæ•´"] = completeness_stats.get("è¾ƒå®Œæ•´", 0) + 1
            elif percentage >= 33:
                completeness_stats["éƒ¨åˆ†"] = completeness_stats.get("éƒ¨åˆ†", 0) + 1
            else:
                completeness_stats["ä¸å®Œæ•´"] = completeness_stats.get("ä¸å®Œæ•´", 0) + 1
    
    logger.info(f"\nğŸ“‹ æ•°æ®å®Œæ•´æ€§ç»Ÿè®¡:")
    for status, count in completeness_stats.items():
        logger.info(f"   {status}: {count} ä¸ªè‰ºæœ¯å®¶")
    
    logger.info(f"\nğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°:")
    logger.info(f"   ğŸ“ ç›®å½•: {output_dir}/")
    logger.info(f"   ğŸ“„ æ±‡æ€»æ–‡ä»¶: {summary_filename}")
    logger.info(f"   ğŸ“„ å•ä¸ªæ–‡ä»¶: {output_dir}/[artist_name].json")
    
    logger.info(f"\nğŸ¸ Fuji Rock 2025 è‰ºæœ¯å®¶æ•°æ®æ”¶é›†å®Œæˆï¼")

if __name__ == "__main__":
    asyncio.run(main()) 