#!/usr/bin/env python3
"""
Fuji Rock 2025 æ•°æ®å¯¼å…¥è„šæœ¬

å°†æ”¶é›†åˆ°çš„è‰ºæœ¯å®¶æ•°æ®æ‰¹é‡å¯¼å…¥åˆ° Supabase æ•°æ®åº“ä¸­ã€‚

ä½¿ç”¨æ–¹æ³•ï¼š
python3 scripts/import_fuji_rock_data.py
"""

import asyncio
import logging
import sys
import os
import json
from datetime import datetime
from typing import List, Dict, Any

# é¦–å…ˆåŠ è½½ç¯å¢ƒå˜é‡ï¼ˆåœ¨å¯¼å…¥ä»»ä½•é…ç½®ä¹‹å‰ï¼‰
from dotenv import load_dotenv
load_dotenv()

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('fuji_rock_data_import.log')
    ]
)

logger = logging.getLogger(__name__)

async def import_artist_data(artist_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    å¯¼å…¥å•ä¸ªè‰ºæœ¯å®¶çš„æ•°æ®åˆ°æ•°æ®åº“
    
    Args:
        artist_data: è‰ºæœ¯å®¶æ•°æ®å­—å…¸
        
    Returns:
        Dict: å¯¼å…¥ç»“æœ
    """
    from services.artist_db_service import artist_db_service
    from services.ai_description_db_service import ai_description_db_service
    from services.song_db_service import song_db_service
    
    artist_name = artist_data.get("artist_name", "Unknown")
    logger.info(f"ğŸ¤ å¼€å§‹å¯¼å…¥ {artist_name} çš„æ•°æ®...")
    
    result = {
        "artist_name": artist_name,
        "imported_at": datetime.now().isoformat(),
        "success": True,
        "errors": [],
        "steps_completed": []
    }
    
    try:
        data = artist_data.get("data", {})
        
        # 1. å‡†å¤‡è‰ºæœ¯å®¶åŸºæœ¬ä¿¡æ¯
        artist_info = {
            "name": artist_name,
            "is_fuji_rock_artist": True
        }
        
        # æ·»åŠ  Wikipedia æ•°æ®
        if "wikipedia" in data:
            wiki_data = data["wikipedia"]
            artist_info.update({
                "wiki_data": wiki_data,
                "wiki_extract": wiki_data.get("extract", ""),
                "wiki_last_updated": datetime.now().isoformat()
            })
            result["steps_completed"].append("wikipedia_data")
        
        # æ·»åŠ  Spotify æ•°æ®
        if "spotify" in data:
            spotify_data = data["spotify"]
            artist_info.update({
                "spotify_id": spotify_data.get("id"),
                "genres": spotify_data.get("genres", [])
            })
            result["steps_completed"].append("spotify_data")
        
        # 2. åˆ›å»ºæˆ–æ›´æ–°è‰ºæœ¯å®¶è®°å½•
        logger.info(f"  ğŸ“ åˆ›å»ºè‰ºæœ¯å®¶è®°å½•...")
        artist_result = await artist_db_service.create_artist(artist_info)
        
        if not artist_result.get("success"):
            # å°è¯•æ›´æ–°ç°æœ‰è®°å½•
            existing_artists = await artist_db_service.search_artists(artist_name)
            if existing_artists.get("success") and existing_artists["data"]:
                artist_id = existing_artists["data"][0]["id"]
                artist_result = await artist_db_service.update_artist(artist_id, artist_info)
            else:
                raise Exception(f"Failed to create/update artist: {artist_result.get('error')}")
        
        artist_id = artist_result["data"]["id"]
        result["artist_id"] = artist_id
        result["steps_completed"].append("artist_created")
        logger.info(f"    âœ… è‰ºæœ¯å®¶è®°å½•åˆ›å»ºæˆåŠŸ (ID: {artist_id})")
        
        # 3. å¯¼å…¥æ­Œæ›²æ•°æ®
        if "spotify" in data and "top_tracks" in data["spotify"]:
            logger.info(f"  ğŸµ å¯¼å…¥çƒ­é—¨æ­Œæ›²...")
            tracks = data["spotify"]["top_tracks"]
            
            songs_data = []
            for track in tracks:
                song_info = {
                    "title": track.get("name", ""),
                    "artist_id": artist_id,
                    "spotify_id": track.get("id"),
                    "duration_ms": track.get("duration_ms"),
                    "popularity": track.get("popularity"),
                    "preview_url": track.get("preview_url"),
                    "external_urls": track.get("external_urls", {}),
                    "is_fuji_rock_related": True
                }
                songs_data.append(song_info)
            
            if songs_data:
                songs_result = await song_db_service.batch_create_songs(songs_data)
                if songs_result.get("success"):
                    result["steps_completed"].append("songs_imported")
                    logger.info(f"    âœ… å¯¼å…¥ {len(songs_data)} é¦–æ­Œæ›²æˆåŠŸ")
                else:
                    result["errors"].append(f"Songs import failed: {songs_result.get('error')}")
                    logger.warning(f"    âš ï¸ æ­Œæ›²å¯¼å…¥å¤±è´¥: {songs_result.get('error')}")
        
        # 4. å¯¼å…¥ AI æè¿°
        if "ai_description" in data:
            logger.info(f"  ğŸ¤– å¯¼å…¥ AI æè¿°...")
            ai_data = data["ai_description"]
            
            description_info = {
                "artist_id": artist_id,
                "description": ai_data.get("description", ""),
                "style_intensity": 7,
                "language": "zh",
                "model_used": "deepseek-r1-250120",
                "prompt_version": "v1.0",
                "metadata": {
                    "source": "fuji_rock_2025_collection",
                    "collection_date": artist_data.get("collected_at")
                }
            }
            
            ai_result = await ai_description_db_service.create_description(description_info)
            if ai_result.get("success"):
                result["steps_completed"].append("ai_description_imported")
                logger.info(f"    âœ… AI æè¿°å¯¼å…¥æˆåŠŸ")
            else:
                result["errors"].append(f"AI description import failed: {ai_result.get('error')}")
                logger.warning(f"    âš ï¸ AI æè¿°å¯¼å…¥å¤±è´¥: {ai_result.get('error')}")
        
        # 5. è®¡ç®—å¯¼å…¥å®Œæ•´æ€§
        total_steps = 4  # artist, songs, ai_description, completion
        completed_steps = len(result["steps_completed"])
        result["import_completeness"] = {
            "completed": completed_steps,
            "total": total_steps,
            "percentage": (completed_steps / total_steps) * 100
        }
        
        logger.info(f"âœ… {artist_name} æ•°æ®å¯¼å…¥å®Œæˆ ({completed_steps}/{total_steps} æ­¥éª¤)")
        
    except Exception as e:
        result["success"] = False
        result["errors"].append(f"Import error: {str(e)}")
        logger.error(f"âŒ {artist_name} æ•°æ®å¯¼å…¥å¤±è´¥: {str(e)}")
    
    return result

async def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸ¸ Fuji Rock 2025 æ•°æ®å¯¼å…¥å¼€å§‹")
    logger.info("="*80)
    
    # è¯»å–æ”¶é›†åˆ°çš„æ•°æ®
    data_file = "data/fuji_rock_2025/fuji_rock_2025_summary.json"
    
    if not os.path.exists(data_file):
        logger.error(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_file}")
        logger.error("è¯·å…ˆè¿è¡Œ scripts/collect_fuji_rock_data.py æ”¶é›†æ•°æ®")
        return
    
    logger.info(f"ğŸ“– è¯»å–æ•°æ®æ–‡ä»¶: {data_file}")
    
    with open(data_file, 'r', encoding='utf-8') as f:
        summary_data = json.load(f)
    
    artists_data = summary_data.get("artists", [])
    total_artists = len(artists_data)
    
    if total_artists == 0:
        logger.error("âŒ æ²¡æœ‰æ‰¾åˆ°è‰ºæœ¯å®¶æ•°æ®")
        return
    
    logger.info(f"ğŸ“ å°†å¯¼å…¥ {total_artists} ä¸ªè‰ºæœ¯å®¶çš„æ•°æ®")
    
    # æµ‹è¯•æ•°æ®åº“è¿æ¥
    logger.info("ğŸ”— æµ‹è¯•æ•°æ®åº“è¿æ¥...")
    try:
        from services.database_service import database_service
        health_result = await database_service.health_check()
        if not health_result.get("success"):
            logger.error(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {health_result.get('error')}")
            return
        logger.info("âœ… æ•°æ®åº“è¿æ¥æ­£å¸¸")
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“è¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}")
        return
    
    # å¼€å§‹å¯¼å…¥æ•°æ®
    all_results = []
    successful_imports = 0
    
    for i, artist_data in enumerate(artists_data, 1):
        if not artist_data.get("success"):
            logger.warning(f"âš ï¸ è·³è¿‡å¤±è´¥çš„æ•°æ®æ”¶é›†: {artist_data.get('artist_name')}")
            continue
        
        logger.info(f"\n{'='*60}")
        logger.info(f"è¿›åº¦: {i}/{total_artists} - {artist_data.get('artist_name')}")
        logger.info(f"{'='*60}")
        
        result = await import_artist_data(artist_data)
        all_results.append(result)
        
        if result["success"]:
            successful_imports += 1
        
        # å¤„ç†é—´éš”ï¼ˆé¿å…æ•°æ®åº“å‹åŠ›ï¼‰
        if i < total_artists:
            logger.info("â³ ç­‰å¾… 1 ç§’...")
            await asyncio.sleep(1)
    
    # ä¿å­˜å¯¼å…¥ç»“æœ
    import_summary = {
        "import_info": {
            "total_artists": total_artists,
            "successful_imports": successful_imports,
            "success_rate": (successful_imports / total_artists) * 100,
            "imported_at": datetime.now().isoformat()
        },
        "results": all_results
    }
    
    # åˆ›å»ºå¯¼å…¥ç»“æœç›®å½•
    results_dir = "data/import_results"
    os.makedirs(results_dir, exist_ok=True)
    
    results_filename = f"{results_dir}/fuji_rock_2025_import_results.json"
    with open(results_filename, 'w', encoding='utf-8') as f:
        json.dump(import_summary, f, ensure_ascii=False, indent=2)
    
    # è¾“å‡ºæœ€ç»ˆç»“æœ
    logger.info(f"\n{'='*80}")
    logger.info("ğŸµ æ•°æ®å¯¼å…¥å®Œæˆï¼ç»“æœæ‘˜è¦:")
    logger.info(f"{'='*80}")
    
    logger.info(f"ğŸ“Š æ€»è®¡: {total_artists} ä¸ªè‰ºæœ¯å®¶")
    logger.info(f"âœ… æˆåŠŸ: {successful_imports}")
    logger.info(f"âŒ å¤±è´¥: {total_artists - successful_imports}")
    logger.info(f"ğŸ“ˆ æˆåŠŸç‡: {(successful_imports / total_artists * 100):.1f}%")
    
    # å¯¼å…¥å®Œæ•´æ€§ç»Ÿè®¡
    completeness_stats = {}
    for result in all_results:
        if result["success"] and "import_completeness" in result:
            percentage = result["import_completeness"]["percentage"]
            if percentage == 100:
                completeness_stats["å®Œæ•´"] = completeness_stats.get("å®Œæ•´", 0) + 1
            elif percentage >= 75:
                completeness_stats["è¾ƒå®Œæ•´"] = completeness_stats.get("è¾ƒå®Œæ•´", 0) + 1
            elif percentage >= 50:
                completeness_stats["éƒ¨åˆ†"] = completeness_stats.get("éƒ¨åˆ†", 0) + 1
            else:
                completeness_stats["ä¸å®Œæ•´"] = completeness_stats.get("ä¸å®Œæ•´", 0) + 1
    
    logger.info(f"\nğŸ“‹ å¯¼å…¥å®Œæ•´æ€§ç»Ÿè®¡:")
    for status, count in completeness_stats.items():
        logger.info(f"   {status}: {count} ä¸ªè‰ºæœ¯å®¶")
    
    logger.info(f"\nğŸ’¾ å¯¼å…¥ç»“æœå·²ä¿å­˜åˆ°:")
    logger.info(f"   ğŸ“„ ç»“æœæ–‡ä»¶: {results_filename}")
    
    logger.info(f"\nğŸ¸ Fuji Rock 2025 æ•°æ®å¯¼å…¥å®Œæˆï¼")

if __name__ == "__main__":
    asyncio.run(main()) 