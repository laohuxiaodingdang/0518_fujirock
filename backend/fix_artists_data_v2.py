#!/usr/bin/env python3
"""
æ‰¹é‡ä¿®å¤è‰ºæœ¯å®¶æ•°æ®è„šæœ¬ V2 - æ”¹è¿›ç‰ˆæœ¬
å¤„ç†Wikipediaæœç´¢å¤±è´¥çš„æƒ…å†µï¼Œå¹¶å°è¯•å¤šç§æœç´¢ç­–ç•¥
"""
import asyncio
import os
import httpx
import json
import urllib.parse
from typing import Optional, Dict, Any
from datetime import datetime, timezone
from supabase import create_client, Client
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

def get_supabase_client() -> Client:
    """è·å–Supabaseå®¢æˆ·ç«¯"""
    url = os.getenv("SUPABASE_URL")
    key = os.getenv("SUPABASE_SERVICE_ROLE_KEY") or os.getenv("SUPABASE_ANON_KEY")
    
    if not url or not key:
        raise ValueError("Missing Supabase credentials")
    
    return create_client(url, key)

async def search_wikipedia_enhanced(artist_name: str) -> Optional[Dict[str, Any]]:
    """å¢å¼ºçš„Wikipediaæœç´¢ï¼Œå°è¯•å¤šç§ç­–ç•¥"""
    try:
        async with httpx.AsyncClient(timeout=10.0) as client:
            headers = {
                "User-Agent": "FujiRock2025API/1.0 (https://github.com/example/fujirock)"
            }
            
            # ç­–ç•¥1: ç›´æ¥æœç´¢è‰ºæœ¯å®¶åç§°
            search_url = f"https://zh.wikipedia.org/api/rest_v1/page/summary/{urllib.parse.quote(artist_name)}"
            print(f"      å°è¯•ç›´æ¥æœç´¢: {artist_name}")
            
            response = await client.get(search_url, headers=headers)
            if response.status_code == 200:
                data = response.json()
                if data.get("extract") and len(data["extract"].strip()) > 20:
                    print(f"      âœ… ç›´æ¥æœç´¢æˆåŠŸ")
                    return {
                        "extract": data["extract"],
                        "title": data.get("title", artist_name),
                        "page_url": data.get("content_urls", {}).get("desktop", {}).get("page", ""),
                        "thumbnail": data.get("thumbnail", {}).get("source", "") if data.get("thumbnail") else ""
                    }
            
            # ç­–ç•¥2: ä½¿ç”¨æœç´¢API
            print(f"      å°è¯•æœç´¢API")
            search_api_url = "https://zh.wikipedia.org/api/rest_v1/page/search"
            search_response = await client.get(
                search_api_url,
                params={"q": artist_name, "limit": 3},
                headers=headers
            )
            
            if search_response.status_code == 200:
                search_data = search_response.json()
                if search_data.get("pages"):
                    for page in search_data["pages"][:2]:  # å°è¯•å‰2ä¸ªç»“æœ
                        page_title = page["title"]
                        print(f"      å°è¯•é¡µé¢: {page_title}")
                        
                        detail_url = f"https://zh.wikipedia.org/api/rest_v1/page/summary/{urllib.parse.quote(page_title)}"
                        detail_response = await client.get(detail_url, headers=headers)
                        
                        if detail_response.status_code == 200:
                            data = detail_response.json()
                            if data.get("extract") and len(data["extract"].strip()) > 20:
                                print(f"      âœ… æœç´¢APIæˆåŠŸ: {page_title}")
                                return {
                                    "extract": data["extract"],
                                    "title": data.get("title", page_title),
                                    "page_url": data.get("content_urls", {}).get("desktop", {}).get("page", ""),
                                    "thumbnail": data.get("thumbnail", {}).get("source", "") if data.get("thumbnail") else ""
                                }
            
            # ç­–ç•¥3: å°è¯•è‹±æ–‡Wikipedia
            print(f"      å°è¯•è‹±æ–‡Wikipedia")
            en_search_url = f"https://en.wikipedia.org/api/rest_v1/page/summary/{urllib.parse.quote(artist_name)}"
            en_response = await client.get(en_search_url, headers=headers)
            
            if en_response.status_code == 200:
                data = en_response.json()
                if data.get("extract") and len(data["extract"].strip()) > 20:
                    print(f"      âœ… è‹±æ–‡WikipediaæˆåŠŸ")
                    return {
                        "extract": data["extract"],
                        "title": data.get("title", artist_name),
                        "page_url": data.get("content_urls", {}).get("desktop", {}).get("page", ""),
                        "thumbnail": data.get("thumbnail", {}).get("source", "") if data.get("thumbnail") else ""
                    }
            
            print(f"      âŒ æ‰€æœ‰Wikipediaæœç´¢ç­–ç•¥éƒ½å¤±è´¥")
            return None
            
    except Exception as e:
        print(f"      Wikipediaæœç´¢é”™è¯¯: {str(e)}")
        return None

async def get_spotify_artist_image(spotify_id: str) -> Optional[str]:
    """ä»Spotifyè·å–è‰ºæœ¯å®¶å›¾ç‰‡ - éœ€è¦å®ç°Spotify APIè°ƒç”¨"""
    # è¿™é‡Œéœ€è¦å®ç°Spotify APIè°ƒç”¨
    # æš‚æ—¶è¿”å›Noneï¼Œä½†ä¿ç•™æ¥å£ä¾›åç»­å®ç°
    return None

async def update_artist_data_v2(supabase: Client, artist_id: str, wiki_data: Dict[str, Any] = None, image_url: str = None, mark_attempted: bool = False):
    """æ›´æ–°è‰ºæœ¯å®¶æ•°æ®åˆ°æ•°æ®åº“ - æ”¹è¿›ç‰ˆæœ¬"""
    try:
        update_data = {}
        current_time = datetime.now(timezone.utc).isoformat()
        
        if wiki_data:
            update_data.update({
                "wiki_extract": wiki_data["extract"],
                "wiki_data": wiki_data,
                "wiki_last_updated": current_time
            })
        
        if image_url:
            update_data["image_url"] = image_url
        
        # å¦‚æœæ ‡è®°ä¸ºå·²å°è¯•ä½†å¤±è´¥ï¼Œè®°å½•å°è¯•æ—¶é—´
        if mark_attempted and not wiki_data:
            update_data["wiki_last_updated"] = current_time
        
        # æ€»æ˜¯æ›´æ–° updated_at
        update_data["updated_at"] = current_time
        
        if update_data:
            result = supabase.table("artists").update(update_data).eq("id", artist_id).execute()
            return result.data is not None
        
        return False
        
    except Exception as e:
        print(f"      æ•°æ®åº“æ›´æ–°é”™è¯¯: {str(e)}")
        return False

async def fix_artist_missing_both_v2(supabase: Client, artist: Dict[str, Any]):
    """ä¿®å¤ç¼ºå¤±wikiå’Œimageçš„è‰ºæœ¯å®¶ - æ”¹è¿›ç‰ˆæœ¬"""
    name = artist["name"]
    artist_id = artist["id"]
    spotify_id = artist.get("spotify_id")
    
    print(f"ğŸ”§ ä¿®å¤è‰ºæœ¯å®¶: {name}")
    
    # è·å–Wikipediaæ•°æ®
    wiki_data = await search_wikipedia_enhanced(name)
    
    # ä»Wikipediaè·å–å›¾ç‰‡ï¼ˆå¦‚æœæœ‰ï¼‰
    image_url = None
    if wiki_data and wiki_data.get("thumbnail"):
        image_url = wiki_data["thumbnail"]
        print(f"      ğŸ–¼ï¸  ä»Wikipediaè·å–å›¾ç‰‡")
    
    # å¦‚æœWikipediaæ²¡æœ‰å›¾ç‰‡ï¼Œå°è¯•ä»Spotifyè·å–
    if not image_url and spotify_id:
        print(f"      å°è¯•ä»Spotifyè·å–å›¾ç‰‡")
        spotify_image = await get_spotify_artist_image(spotify_id)
        if spotify_image:
            image_url = spotify_image
            print(f"      ğŸ–¼ï¸  ä»Spotifyè·å–å›¾ç‰‡")
    
    # æ˜¾ç¤ºè·å–åˆ°çš„æ•°æ®
    if wiki_data:
        print(f"      ğŸ“ Wiki: {wiki_data['extract'][:80]}...")
    else:
        print(f"      ğŸ“ Wiki: æœªæ‰¾åˆ°")
    
    if image_url:
        print(f"      ğŸ–¼ï¸  Image: {image_url[:80]}...")
    else:
        print(f"      ğŸ–¼ï¸  Image: æœªæ‰¾åˆ°")
    
    # æ›´æ–°æ•°æ®åº“ - å³ä½¿æ²¡æœ‰æ‰¾åˆ°æ•°æ®ä¹Ÿè¦æ ‡è®°å°è¯•è¿‡
    success = await update_artist_data_v2(
        supabase, 
        artist_id, 
        wiki_data, 
        image_url, 
        mark_attempted=True
    )
    
    if success:
        wiki_status = "âœ…" if wiki_data else "ğŸ”"
        image_status = "âœ…" if image_url else "ğŸ”"
        print(f"      ç»“æœ - Wiki: {wiki_status}, Image: {image_status}")
    else:
        print(f"      âŒ æ•°æ®åº“æ›´æ–°å¤±è´¥")
    
    return success

async def fix_artist_missing_wiki_v2(supabase: Client, artist: Dict[str, Any]):
    """ä¿®å¤åªç¼ºå°‘wikiçš„è‰ºæœ¯å®¶ - æ”¹è¿›ç‰ˆæœ¬"""
    name = artist["name"]
    artist_id = artist["id"]
    
    print(f"ğŸ“ è·å–Wiki: {name}")
    
    # è·å–Wikipediaæ•°æ®
    wiki_data = await search_wikipedia_enhanced(name)
    
    if wiki_data:
        print(f"      ğŸ“ Wiki: {wiki_data['extract'][:80]}...")
    else:
        print(f"      ğŸ“ Wiki: æœªæ‰¾åˆ°")
    
    # æ›´æ–°æ•°æ®åº“
    success = await update_artist_data_v2(
        supabase, 
        artist_id, 
        wiki_data=wiki_data, 
        mark_attempted=True
    )
    
    if success:
        status = "âœ…" if wiki_data else "ğŸ”"
        print(f"      ç»“æœ - Wiki: {status}")
    else:
        print(f"      âŒ æ•°æ®åº“æ›´æ–°å¤±è´¥")
    
    return success

async def main():
    """ä¸»å‡½æ•°"""
    try:
        supabase = get_supabase_client()
        
        # è·å–æ‰€æœ‰Fuji Rockè‰ºæœ¯å®¶
        response = supabase.table("artists").select("*").eq("is_fuji_rock_artist", True).execute()
        
        if not response.data:
            print("No Fuji Rock artists found in database")
            return
        
        artists = response.data
        print(f"Found {len(artists)} Fuji Rock artists in database")
        print("=" * 60)
        
        missing_wiki = []
        missing_image = []
        missing_both = []
        
        for artist in artists:
            name = artist.get('name', 'Unknown')
            wiki_extract = artist.get('wiki_extract')
            image_url = artist.get('image_url')
            
            # æ£€æŸ¥wikiæ•°æ®
            has_wiki = (wiki_extract and 
                       wiki_extract.strip() and 
                       wiki_extract.strip() != "" and
                       len(wiki_extract.strip()) > 10)
            
            # æ£€æŸ¥imageæ•°æ®
            has_image = (image_url and 
                        image_url.strip() and 
                        image_url.strip() != "" and
                        "placeholder" not in image_url.lower() and
                        image_url != "https://via.placeholder.com/300x300?text=No+Image")
            
            if not has_wiki and not has_image:
                missing_both.append(artist)
            elif not has_wiki:
                missing_wiki.append(artist)
            elif not has_image:
                missing_image.append(artist)
        
        print(f"éœ€è¦ä¿®å¤çš„è‰ºæœ¯å®¶: {len(missing_both) + len(missing_wiki) + len(missing_image)}")
        print(f"- ç¼ºå¤±ä¸¤ç§æ•°æ®: {len(missing_both)}")
        print(f"- åªç¼ºå°‘wiki: {len(missing_wiki)}")
        print(f"- åªç¼ºå°‘image: {len(missing_image)}")
        print()
        
        # ä¿®å¤ç¼ºå¤±ä¸¤ç§æ•°æ®çš„è‰ºæœ¯å®¶ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
        if missing_both:
            print("ğŸš¨ ä¿®å¤ç¼ºå¤±ä¸¤ç§æ•°æ®çš„è‰ºæœ¯å®¶:")
            success_count = 0
            for i, artist in enumerate(missing_both):
                print(f"   [{i+1}/{len(missing_both)}]", end=" ")
                success = await fix_artist_missing_both_v2(supabase, artist)
                if success:
                    success_count += 1
                await asyncio.sleep(2)  # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                print()
            print(f"   å®Œæˆ: {success_count}/{len(missing_both)} æˆåŠŸ")
            print()
        
        # ä¿®å¤åªç¼ºå°‘wikiçš„è‰ºæœ¯å®¶ï¼ˆå‰5ä¸ªï¼‰
        if missing_wiki:
            print("ğŸ“ ä¿®å¤ç¼ºå°‘wikiçš„è‰ºæœ¯å®¶ï¼ˆå‰5ä¸ªï¼‰:")
            success_count = 0
            for i, artist in enumerate(missing_wiki[:5]):
                print(f"   [{i+1}/5]", end=" ")
                success = await fix_artist_missing_wiki_v2(supabase, artist)
                if success:
                    success_count += 1
                await asyncio.sleep(2)  # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                print()
            print(f"   å®Œæˆ: {success_count}/5 æˆåŠŸ")
            print()
        
        print("=" * 60)
        print("âœ… ä¿®å¤å®Œæˆï¼")
        print("ğŸ“Š è¿è¡Œ python check_artists_data.py æŸ¥çœ‹æ›´æ–°åçš„çŠ¶æ€")
        print("ğŸ”„ å¦‚éœ€ç»§ç»­ä¿®å¤æ›´å¤šè‰ºæœ¯å®¶ï¼Œå¯å†æ¬¡è¿è¡Œæ­¤è„šæœ¬")
        
    except Exception as e:
        print(f"Error: {str(e)}")
        import traceback
        traceback.print_exc()
        return

if __name__ == "__main__":
    asyncio.run(main()) 