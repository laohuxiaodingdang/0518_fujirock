#!/usr/bin/env python3
"""
è°ƒè¯•æ•°æ®åº“æ›´æ–°é—®é¢˜çš„è„šæœ¬
"""
import asyncio
import os
import httpx
from datetime import datetime, timezone
from supabase import create_client, Client
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

def get_supabase_client() -> Client:
    """è·å–Supabaseå®¢æˆ·ç«¯"""
    url = os.getenv("SUPABASE_URL")
    key = os.getenv("SUPABASE_SERVICE_ROLE_KEY") or os.getenv("SUPABASE_ANON_KEY")
    
    if not url or not key:
        raise ValueError("Missing Supabase credentials")
    
    return create_client(url, key)

async def test_wikipedia_search(artist_name: str):
    """æµ‹è¯•Wikipediaæœç´¢"""
    try:
        async with httpx.AsyncClient(timeout=10.0) as client:
            search_url = f"https://zh.wikipedia.org/api/rest_v1/page/summary/{artist_name}"
            headers = {
                "User-Agent": "FujiRock2025API/1.0 (https://github.com/example/fujirock)"
            }
            
            print(f"ğŸ” æœç´¢Wikipedia: {search_url}")
            response = await client.get(search_url, headers=headers)
            print(f"   çŠ¶æ€ç : {response.status_code}")
            
            if response.status_code == 200:
                data = response.json()
                print(f"   æ‰¾åˆ°é¡µé¢: {data.get('title', 'Unknown')}")
                if data.get("extract"):
                    print(f"   æ‘˜è¦: {data['extract'][:100]}...")
                    return {
                        "extract": data["extract"],
                        "title": data.get("title", artist_name),
                        "page_url": data.get("content_urls", {}).get("desktop", {}).get("page", ""),
                        "thumbnail": data.get("thumbnail", {}).get("source", "") if data.get("thumbnail") else ""
                    }
                else:
                    print("   æ²¡æœ‰æ‰¾åˆ°æ‘˜è¦å†…å®¹")
            else:
                print(f"   æœç´¢å¤±è´¥: {response.text}")
            
            return None
            
    except Exception as e:
        print(f"   Wikipediaæœç´¢é”™è¯¯: {str(e)}")
        return None

async def test_database_update(supabase: Client, artist_id: str, test_data: dict):
    """æµ‹è¯•æ•°æ®åº“æ›´æ–°"""
    try:
        print(f"ğŸ”§ æµ‹è¯•æ›´æ–°è‰ºæœ¯å®¶ {artist_id}")
        print(f"   æ›´æ–°æ•°æ®: {test_data}")
        
        # å°è¯•æ›´æ–°
        result = supabase.table("artists").update(test_data).eq("id", artist_id).execute()
        
        print(f"   è¿”å›ç»“æœ: {result}")
        print(f"   æ•°æ®: {result.data}")
        print(f"   é”™è¯¯: {getattr(result, 'error', None)}")
        
        if result.data:
            print("   âœ… æ›´æ–°æˆåŠŸ")
            return True
        else:
            print("   âŒ æ›´æ–°å¤±è´¥")
            return False
            
    except Exception as e:
        print(f"   âŒ æ›´æ–°å¼‚å¸¸: {str(e)}")
        print(f"   å¼‚å¸¸ç±»å‹: {type(e)}")
        if hasattr(e, '__dict__'):
            print(f"   å¼‚å¸¸è¯¦æƒ…: {e.__dict__}")
        return False

async def main():
    """ä¸»å‡½æ•°"""
    try:
        supabase = get_supabase_client()
        
        # è·å–ä¸€ä¸ªç¼ºå¤±æ•°æ®çš„è‰ºæœ¯å®¶è¿›è¡Œæµ‹è¯•
        print("ğŸ” è·å–æµ‹è¯•è‰ºæœ¯å®¶...")
        response = supabase.table("artists").select("*").eq("name", "ROUTE 17 Rock'n'Roll ORCHESTRA").execute()
        
        if not response.data:
            print("âŒ æ‰¾ä¸åˆ°æµ‹è¯•è‰ºæœ¯å®¶")
            return
        
        artist = response.data[0]
        artist_id = artist["id"]
        artist_name = artist["name"]
        
        print(f"âœ… æ‰¾åˆ°è‰ºæœ¯å®¶: {artist_name}")
        print(f"   ID: {artist_id}")
        print(f"   å½“å‰wiki_extract: {artist.get('wiki_extract', 'None')}")
        print(f"   å½“å‰image_url: {artist.get('image_url', 'None')}")
        print()
        
        # æµ‹è¯•Wikipediaæœç´¢
        print("ğŸ“ æµ‹è¯•Wikipediaæœç´¢...")
        wiki_data = await test_wikipedia_search(artist_name)
        print()
        
        # æµ‹è¯•ç®€å•çš„æ•°æ®åº“æ›´æ–°
        print("ğŸ”§ æµ‹è¯•ç®€å•æ›´æ–°...")
        simple_update = {
            "updated_at": datetime.now(timezone.utc).isoformat()
        }
        await test_database_update(supabase, artist_id, simple_update)
        print()
        
        # æµ‹è¯•wikiæ•°æ®æ›´æ–°
        if wiki_data:
            print("ğŸ”§ æµ‹è¯•Wikiæ•°æ®æ›´æ–°...")
            wiki_update = {
                "wiki_extract": wiki_data["extract"],
                "updated_at": datetime.now(timezone.utc).isoformat()
            }
            await test_database_update(supabase, artist_id, wiki_update)
            print()
        
        # æµ‹è¯•å®Œæ•´æ•°æ®æ›´æ–°
        print("ğŸ”§ æµ‹è¯•å®Œæ•´æ•°æ®æ›´æ–°...")
        full_update = {}
        
        if wiki_data:
            current_time = datetime.now(timezone.utc).isoformat()
            full_update.update({
                "wiki_extract": wiki_data["extract"],
                "wiki_data": wiki_data,
                "wiki_last_updated": current_time,
                "updated_at": current_time
            })
        
        if wiki_data and wiki_data.get("thumbnail"):
            full_update["image_url"] = wiki_data["thumbnail"]
        
        if full_update:
            await test_database_update(supabase, artist_id, full_update)
        else:
            print("   æ²¡æœ‰æ•°æ®å¯æ›´æ–°")
        
    except Exception as e:
        print(f"âŒ ä¸»å‡½æ•°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main()) 